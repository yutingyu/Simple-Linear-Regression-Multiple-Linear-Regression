#● Simple Linear Regression :
#1.Download the file ‘insurance.csv’ from our class Blackboard site.
#2.Read this file into your R environment. Show the step that you used to accomplish this.
setwd("C:/Users/R Coding 2")
insurance<-read.csv('insurance.csv')

#3. Filter the dataframe to create a new dataframe that only contains the records of people who are not smokers. Show the code that you used to do this.
#-- You will use this new dataframe for the rest of the assignment --
library(dplyr)
newins<-filter(insurance,smoker=='no')
View(newins)

#4.Using ggplot, create a scatterplot to depict the relationship between the input variable age and the output variable charges. Show your scatterplot, along with the code that
#you used to build it. What does this scatterplot suggest about the relationship between the two variables? Why (or why not) does this make intuitive sense to you
plot(newins$charges~newins$age,main="Relationship between age and charges",ylab='charges',xlab='age')
library(ggplot2)
A<-ggplot(data=newins,aes(x=age,y=charges))+geom_point()+ggtitle('Relationship between age and charges')+xlab('age')+ylab('charges')+theme(plot.title=element_text(hjust=0.5))
A

#5. Find the correlation between age and charges . 
cor(newins$age, newins$charges,use='complete.obs')

#6. Using your assigned seed value, create a data partition. Assign approximately 60% of the records to your training set, and the other 40% to your validation set. Show the code that you used to do this.
set.seed(400)
train.index<-sample(row.names(newins), 0.6*dim(newins)[1])
valid.index<-setdiff(row.names(newins),train.index)
train.df<-newins[train.index,]
valid.df<-newins[valid.index,]
View(train.df)

#7. Using your training set, create a simple linear regression model. 
newins.lm<-lm(charges~age,data=train.df)
options(scipen=999,digits=1)
summary(newins.lm)
print(newins.lm)

#8. What is the regression equation generated by your model?
-2059+274*20

#9. Using the accuracy() function from the forecast package, assess the accuracy of your model against both the training set and the validation set. What do you notice about these results? Describe your findings in a couple of sentences.
install.packages("forecast")
library(forecast)
predict1<-predict(newins.lm,train.df)
accuracy(predict1,train.df$charges)

predict2<-predict(newins.lm, valid.df)
accuracy(predict2, valid.df$charges)

#● Multiple Linear Regression :For this part of the assignment, use the same training set and the same validation set that you used in Part I.
#1.Create a scatterplot matrix that depicts the relationships among all of the numerical variables that you might use as predictors (use your training set to build this). Show the code you used to build the scatterplot matrix, and show your scatterplot matrix.
# Describe your scatterplot matrix in a few sentences. Are there any variable relationships that suggest that multicollinearity could be an issue here?
View(train.df)
library(dplyr)
library(GGally)
str(train.df)
td<-subset(train.df,select=c(age, bmi ,children, charges))
ggpairs(td)

#3. Create dummy variables for any categorical predictors in the data set, and show the code that you used to do this.
#a. To complete this step, you will need to create dummy variables for the categorical variables in your training set and your validation set.
library(caret)
data=train.df
View(train.df)
dmy<-dummyVars("~region", data=train.df,fullRank = TRUE)
trdf<-data.frame(predict(dmy,newdata=train.df))
trdf
newtrain.df<-cbind(train.df,trdf)
newtrain.df


library(caret)
data=valid.df
dmy<-dummyVars("~region",data=valid.df,fullRank=TRUE) #dummy¿ÉÒÔ×Ô¶¯Ê¶±ðËùÓÐcharacter£¬È»ºó±ä»¯¡£
trvf<-data.frame(predict(dmy,newdata=valid.df))
trvf
newvalid.df<-cbind(valid.df,trvf)
newvalid.df

#4. Using backward elimination, build a multiple regression model with the data in your training set, with the goal of predicting the charges variable. (Start with all of the potential predictors).
lm2<-lm(charges~age+sex+bmi+children+region, data=train.df)
lmstep<-step(lm2,direction='backward')
summary(lmstep)

#5. Based in part on what was recommended by the backward elimination process, and in part on your judgement, which variables will you keep?

#6  Using the variables that you will keep, build a multiple linear regression model.
lm3<-lm(charges~age+sex+children+region, data=train.df)
summary(lmstep)

#7. Make up a fictional person, and assign this person attributes for each of the predictors in your model. What does your model predict that this person’s health care charges will be?

#8. Using the accuracy() function from the forecast package, assess the accuracy of your model against both the training set and the validation set. What do you notice about these results? Describe your findings in a couple of sentences.
library(forecast)
predict3<-predict(lm3,train.df)
accuracy(predict3,train.df$charges)
predict4<-predict(lm3,valid.df)
accuracy(predict4,valid.df$charges)
mean(train.df$charges)
mean(valid.df$charges)
4343/8413
4926/8467
0.5/0.6



